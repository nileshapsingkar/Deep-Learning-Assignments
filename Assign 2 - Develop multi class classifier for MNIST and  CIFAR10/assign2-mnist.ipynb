{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[20])\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "num_classes = 10  # There are 10 classes (digits0-9)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nilesh\\anaconda3\\envs\\mllab\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 80ms/step - accuracy: 0.1342 - loss: 2.2826 - val_accuracy: 0.4458 - val_loss: 2.2086\n",
      "Epoch 2/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 75ms/step - accuracy: 0.2885 - loss: 2.2000 - val_accuracy: 0.6237 - val_loss: 2.0941\n",
      "Epoch 3/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.4309 - loss: 2.0886 - val_accuracy: 0.6876 - val_loss: 1.9334\n",
      "Epoch 4/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.5330 - loss: 1.9325 - val_accuracy: 0.7420 - val_loss: 1.7175\n",
      "Epoch 5/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.5959 - loss: 1.7290 - val_accuracy: 0.7788 - val_loss: 1.4588\n",
      "Epoch 6/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.6441 - loss: 1.4996 - val_accuracy: 0.8064 - val_loss: 1.2013\n",
      "Epoch 7/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.6728 - loss: 1.2855 - val_accuracy: 0.8255 - val_loss: 0.9894\n",
      "Epoch 8/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.7015 - loss: 1.1084 - val_accuracy: 0.8346 - val_loss: 0.8341\n",
      "Epoch 9/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 74ms/step - accuracy: 0.7260 - loss: 0.9736 - val_accuracy: 0.8459 - val_loss: 0.7231\n",
      "Epoch 10/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 74ms/step - accuracy: 0.7401 - loss: 0.8878 - val_accuracy: 0.8544 - val_loss: 0.6445\n",
      "Epoch 11/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.7591 - loss: 0.8144 - val_accuracy: 0.8624 - val_loss: 0.5866\n",
      "Epoch 12/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.7767 - loss: 0.7575 - val_accuracy: 0.8672 - val_loss: 0.5423\n",
      "Epoch 13/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.7829 - loss: 0.7206 - val_accuracy: 0.8727 - val_loss: 0.5079\n",
      "Epoch 14/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.7981 - loss: 0.6668 - val_accuracy: 0.8777 - val_loss: 0.4803\n",
      "Epoch 15/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.8020 - loss: 0.6504 - val_accuracy: 0.8815 - val_loss: 0.4577\n",
      "Epoch 16/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.8071 - loss: 0.6253 - val_accuracy: 0.8854 - val_loss: 0.4382\n",
      "Epoch 17/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.8168 - loss: 0.6032 - val_accuracy: 0.8872 - val_loss: 0.4221\n",
      "Epoch 18/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.8176 - loss: 0.5910 - val_accuracy: 0.8900 - val_loss: 0.4081\n",
      "Epoch 19/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.8259 - loss: 0.5700 - val_accuracy: 0.8921 - val_loss: 0.3954\n",
      "Epoch 20/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.8300 - loss: 0.5538 - val_accuracy: 0.8946 - val_loss: 0.3847\n",
      "Epoch 21/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.8371 - loss: 0.5318 - val_accuracy: 0.8960 - val_loss: 0.3740\n",
      "Epoch 22/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.8431 - loss: 0.5170 - val_accuracy: 0.8982 - val_loss: 0.3652\n",
      "Epoch 23/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.8409 - loss: 0.5150 - val_accuracy: 0.8997 - val_loss: 0.3583\n",
      "Epoch 24/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.8452 - loss: 0.5051 - val_accuracy: 0.9015 - val_loss: 0.3497\n",
      "Epoch 25/25\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.8522 - loss: 0.4872 - val_accuracy: 0.9031 - val_loss: 0.3429\n",
      "The model has successfully trained\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "\n",
    "print(\"The model has successfully trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model as mnist.h5\n",
      "Test loss: 0.34292715787887573\n",
      "Test accuracy: 0.9031000137329102\n"
     ]
    }
   ],
   "source": [
    "model.save('mnist.h5')\n",
    "print(\"Saving the model as mnist.h5\")\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import win32gui\n",
    "from PIL import ImageGrab, Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_digit(img):\n",
    "    #resize image to 28x28 pixels\n",
    "    img = img.resize((28,28))\n",
    "    #convert rgb to grayscale\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img)\n",
    "    #reshaping to support our model input and normalizing\n",
    "    img = img.reshape(1,28,28,1)\n",
    "    img = img/255.0\n",
    "    #predicting the class\n",
    "    res = model.predict([img])[0]\n",
    "    return np.argmax(res), max(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class App(tk.Tk):\n",
    "\n",
    "    def __init__(self):\n",
    "        tk.Tk.__init__(self)\n",
    "        self.x = self.y = 0\n",
    "        # Creating elements\n",
    "        self.canvas = tk.Canvas(self, width=300, height=300, bg = \"white\", cursor=\"cross\")\n",
    "        self.label = tk.Label(self, text=\"Thinking..\", font=(\"Helvetica\", 48))\n",
    "        self.classify_btn = tk.Button(self, text = \"Recognise\", command =self.classify_handwriting) \n",
    "        self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n",
    "        # Grid structure\n",
    "        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n",
    "        self.label.grid(row=0, column=1,pady=2, padx=2)\n",
    "        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n",
    "        self.button_clear.grid(row=1, column=0, pady=2)\n",
    "        #self.canvas.bind(\"<Motion>\", self.start_pos)\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
    "\n",
    "    def clear_all(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "\n",
    "    def classify_handwriting(self):\n",
    "        HWND = self.canvas.winfo_id() # get the handle of the canvas\n",
    "        rect = win32gui.GetWindowRect(HWND) # get the coordinate of the canvas\n",
    "        im = ImageGrab.grab(rect)\n",
    "        digit, acc = predict_digit(im)\n",
    "        self.label.configure(text= str(digit)+', '+ str(int(acc*100))+'%')\n",
    "\n",
    "    def draw_lines(self, event):\n",
    "        self.x = event.x\n",
    "        self.y = event.y\n",
    "        r=8\n",
    "        self.canvas.create_oval(self.x-r, self.y-r, self.x + r, self.y + r, fill='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    }
   ],
   "source": [
    "app = App()\n",
    "\n",
    "mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
